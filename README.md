Measuring Diversity Analytics Through Survival Functions: 
An attempt to identify structural or unconscious bias using commonly collected people data

The objective of this project is to explore whether commonly collected people data and survival analysis can be used to indicate group differences that may help in identifying instances of structural or unconscious bias.  
Commonly used Diversity, Equity, Inclusion, and Belonging (DEIB) analytics often focus on survey results or on reported demographic headcounts.  Although those are useful, they may overlook some indicators of structural or unconscious bias.  Using the Cox Proportional Hazard model may help identify groups with these problems, though such analysis will not identify the specific bias each group faces.  Identifying these groups can be useful indicators to help HR teams focus their efforts both in identifying issues directly and/or in balancing against the bias.

Current Problem
Across corporations there are persistent problems around hiring and retention of underrepresented groups in categories such as gender or race.  Of S&P 500 companies, the gender pay gap has grown from 12% to 25% between men and women executives from 2018 to 2022, partially due to males owning a disproportional share of equity (Green, 2022).  Although whites only account for 64% of entry-level workers, they comprise 85% of top executives, while Blacks and Hispanics hold only 2% and 3% of executive positions respectively (Stevens, 2020). 
Legal protections and internal Human Resources audits do exist for some disenfranchised groups, but those measures have not created equity.  Other groups are unprotected by law, or even when considered a “protected class” are not considered in HR analytics.  Although analyses of employees by gender and race may be the most common calculations done by Human Resources teams, those methods are rarely generalized to other demographics.

Common Solutions
There is no consistent method of demographic data collection or storage across the 7.7 million establishments in America that have at least one employee (Kehoe, 2019).  Companies that participate in the United States Equal Employment Opportunity categorizations (Equal Employment Opportunity Tabulation Frequently Asked Questions, 2022) will follow certain norms for collecting data about gender and race, though those may not be the demographic breakdowns that are required to find specific bias.  Furthermore, there are not universally agreed upon standards in Human Resources data analysis.  Methods of reporting or regression analysis are rarely shared outside of the organizations that use them.  DEIB professionals may find value in an analysis flexible enough that it can be used on any demographic dataset collected and also consistent enough to provide results that can be compared across groups (provided the data reflects the same type of demographic information).
Reporting/Dashboards
Reporting is the simplest and possibly most common approach to using people data for DEIB efforts.  Organizations can group employees by the demographic data already collected.  This can easily be expressed in a chart or graph.   In this example, Mercer shows a sample DEIB dashboard using the Workday HRIS (Marsh McLennan, n.d.):
This method visually displays data, but it struggles in identifying problems.  Reporting that shows the number of employees of a specific demographic group often gives no indication whether those numbers represent a good or bad situation.  There is not easily available market data for comparison, which would show if any demographic group might be over-represented or under-represented.  In some countries government geographic demographic data is available, but it is not broken down by job type to the level of precision that is generally needed to match to employee populations.  Most importantly, there is no indication if differences in the relative size of demographic groups are due to a real problem or due to random chance.

Surveys
Directly asking employees their viewpoints allows for focused feedback on specific issues.  Employee surveys and pulse surveys can quickly get opinions from a population, indicating which issues are important.  Culture Amp gives this example of DEIB survey results, looking at Inclusion in comparison to other factors (Culture Amp, n.d.):
The value of surveys—their specificity, as well as their reliance on the opinions of survey takers—comes with challenges.  Respondents may not understand or have the same definition of specific words/phrases used in a survey, especially if they are taking a survey in a language that they do not natively speak. Surveys in multiple languages risk creating differences due to the imperfect translation of complex ideas or terms.  Even when a participant understands a question in the same way as the question writer, the participant may not feel comfortable honestly responding and instead pick a more socially desirable answer.  Professional survey writers have methods to minimize these hurdles, but developing those skills or hiring consultants requires more resources.  Employees may experience survey fatigue if they have to take surveys frequently, or if the surveys they take are too long.  In addition, many employees may not be aware of the structural or unconscious bias around them, so those problems may not show up in survey results even if they exist in the workforce.

Correlation Analysis
More advanced HR Analytical teams can build correlation analysis models to see how two data sets are related.  Comparing demographic data or survey responses to turnover may indicate that certain groups or people with certain feelings are more likely to quit.  The Workday HRIS has built-in functionality that tests correlation on a limited number of pre-defined dimensions, as shown by Software Connect in this example (SoftwareConnect, 2022):
If done manually (such as in Excel or in a statistical programs), correlation analysis can be overwhelming for some HR teams.  There are multiple methods (such as Pearson correlation coefficient, Kendall rank correlation coefficient, Spearman's rank correlation coefficient, or intraclass correlation) that have different parametric assumptions.  The use or misuse of these different methods can lead to results that are often not comparable when run by different HR employees.  In most of these methods, responses can indicate the relative relationship between two datasets, but they do not show you how that relationship evolves over time.

What is Being Overlooked
Although the above methods can identify some problems in an employee population, there are many types of bias they would not find.  Reporting and surveys would struggle to identify structural or unconscious bias.  Correlation analysis is sufficiently rigorous to find indications of these biases, but completing such analyses would require a great deal of manual work in data cleaning and in finding the appropriate model.  To understand what method can best be used to pinpoint these issues, we need to define what we mean by structural bias and unconscious bias.

Structural Bias
As Frantz Fanon stated, “The habit of considering racism as a mental quirk, as a psychological flaw, must be abandoned.”  Eduardo Bonilla-Silva continues this argument, proposing that education is the logical pill to solve racism only if we assume racism is an irrational viewpoint.  If we instead understand there exists a structural framework, then racism is its “normal” outcome.  From that view, the only cure to stop racism is to remove the racial organization of society (Silva 1997).  This corresponds to Donald Tomaskovic-Devey’s conclusion that since there is “strong evidence that the degree of discrimination against (a population) rises when the size of their relative population rises[,]...attempts at cultural change through antiracist education are most likely to find receptive audiences in those places where they are the least necessary” (Hanson & Tomaskovic-Devey, 1994).
If we accepted Tomaskovic-Devey's definition, searching for such evidence within a given organizational environment requires different analytical techniques than are typically used.  The Cox Proportional Hazard approach (proposed later in this paper) attempts to implement analytics based on Tomaskovic-Devey’s conclusions: if a disenfranchised population’s growth may increase racism against it, a method other than headcount must be used to identify bias.  If such an analytical approach can find indications of discrimination, especially based on factors other than population size, it may be a more effective tool in dismantling structural racism than the contemporary company practice of headcount reporting and generalized education.
For simplicity, this paper will follow the definition of structural racism proposed by Williams et al. as “the processes of racism that are embedded in laws (local, state, and federal), policies, and practices of society and its institutions that provide advantages to racial groups deemed as superior, while differentially oppressing, disadvantaging, or otherwise neglecting racial groups viewed as inferior” (Williams et al., 2019).  This is relevant to Human Resources teams who write “polices and practices” of our work “societies.”  Human Resources interacts with the “disadvantaged” and “neglected groups” when they are candidates, workers, or those rejected from employment in our organizations. 
Unconscious Bias 
Bias, structural or otherwise, may be conscious or unconscious.  Direct Human Resources responses to bias are often based on blatant, conscious bias: when a worker engages in a clearly racist activity, Human Resources works to correct the behavior of the worker through training, performance improvement plans, or termination.  Unconscious bias is often less obvious to identify and thus harder to correct.
Implicit attitudes (or unconscious bias), as defined by Jennifer Kim and Loriann Roberson, “refers to the automatic, spontaneous associations, thoughts, and evaluations we make about members of a particular” group (Kim & Roberson, 2022).  Identifying spontaneous associations or thoughts through traditional Human Resources analytics (funnel analysis, bonus distribution, etc.) would be challenging or even impossible depending on the dataset.  Identifying unconscious bias based on individual interactions (as we do with blatant racism) would also be challenging, since both the biased person and the person being biased against may not be able to identify the problem.  
Generalization
Conscious and unconscious bias may have different causes, but the results are often the same.  It is equally detrimental to a candidate to be rejected from a position due to overt racism, structural racism, and/or unconscious bias.  For the proposed analysis, we are searching for any indication of a biased environment, even if it can not identify the direct cause of the bias.  Identifying indicators of structural or unconscious bias that are currently being overlooked will provide our Human Resources teams direction to further investigate or to balance against that bias.
We will also consider that a biased environment may create similar indicators in different biased populations.  For example, a group that is biased against Hispanic employees may see that Hispanic employees have shorter tenure there, and a group that is biased against women may see the same for women employees. Headcount reporting, surveys, and even correlation analysis are usually not flexible enough to identify bias based on different types of demographic data collected.  For the remainder of the paper we will use the term “bias” to incorporate structural or unconscious negative pressure against any disenfranchised group based on their demographics.
Survival Analytics
Although some types of bias may be challenging to identify using standard Human Resources data, we may be able to identify bias based on the effects of the environment it creates.  We propose that tenure, or how long a worker continues at their organization, can be a useful tool in identifying bias.  If a worker experiences negative bias, they are incentivized to leave the organization more quickly.  We can thus measure the effects (i.e., shorter tenure) that the biased environment creates.  Statistically significant shorter tenure of a historically oppressed population does not prove bias; for example, these employees could be leaving sooner since they are more sought after, but just like any indicator, survival analysis can be used as a tool for Human Resources teams. 
Tenure can be calculated by multiple methods.  We are proposing to use a survival model to identify tenure based on demographic data.  Keith McNulty (McNulty, 2021) speaks about the value of survival analysis on turnover data since standard regression models are “only able to infer conclusions about the likelihood of the event having occurred as at the end of the period of study.  We cannot make inferences about the likelihood of the event throughout the period of study.”  This encourages us to use survival analysis instead of other regression testing for demographic data, since we are looking to better understand someone’s experience over time, not just whether they will remain at an organization at a specific moment in time.
Cox Proportional Hazard Model
David Cox developed the Cox proportional hazards model in 1972 to estimate covariate effects with proportional hazards assumptions (Deo et al., 2021).  The model uses a “hazard rate” to measure a risk that a group will not survive, based on how long they have already survived (LaMorte, 2016).  Due to its high level of flexibility, the model has been the most widely used analysis for time-to-event curves of clinical studies (Singh & Mukhopadhyay, 2011).  
The model is already being used in Human Resources, though not widely.  Keith McNulty has written about how to use the model for turnover analysis in his book Handbook of Regression Modeling in People Analytics (McNulty, 2021).  This area could be explored further, using the analysis to extrapolate different results based on the type of termination.  Alternatively, it could be used to predict what factors are contributing to promotions or bonuses.
Cox Proportional Hazard Benefits
The Cox proportional hazards model is a regression model that works both for quantitative and for categorical variables, which is useful with Human Resources datasets.  Unlike some other survival models, the Cox model assesses simultaneous effects from several risk factors, giving it greater flexibility for workers with intersectional identities, who may fall into multiple demographic categories that are discriminated against (Cox Proportional-Hazards Model, n.d.).
Cox Proportional Hazard Limitations
When looking at the hazard of two individuals, the Cox model assumes that the hazard curves don’t cross and are always proportional to each other (McNulty, 2021).  This should generally be true for the DEIB applications we are looking at, since we assume the bias factor is irrelevant to time.  Specifically, the environment created from structural or unconscious bias has a general cumulative affect (that is, it is not seasonal and does not regularly fluctuate).
Applicability to DEIB
The Cox Proportional Hazard model solves many of the hurdles that current DEIB analytics face.  Unlike traditional reporting/dashboards, it identifies areas where a problem may exist.  It uses passive data so it does not take time away from the employees.  It can find indicators of bias when neither the perpetrator or victim knows it exists.  It has a greater flexibility than general correlation analysis, making it easier to implement.  
DEIB data is complex and leads to challenging analytics, in ways the Cox model can help solve.  Some organizations collect gender as binary data (i.e., male, female), although other companies allow for more options.  The EEO codes for race break up the population into some very large groups and some very small groups.  Other factors we’d use to identify correlation (like compensation, level, division) may vary depending on the organization.  The Cox model is well suited to a wide variety of data types: nominal, ordinal, discrete, or continuous.
Unlike correlation analysis, the Cox model also provides analysis over a period of time.  When thinking about an environment that adds pressure on someone to leave based on their demographic identity, it may be very useful to understand how such an environment operates over time.  Early in employment, employees may feel very positive toward the organization they just joined.  It may take time to understand the problems that exist there or to feel underlying pressures.  By seeing when the drop off is taking place, it may help HR teams more easily identify problems or add extra support to employees at the times of highest risk.
Model Implementation
The Cox Proportional Hazard model can be implemented in multiple systems.  For simplicity we use the coding language R here since it is a free software platform developed for statistical methods.
After organizing the data and running the needed calculations, we can verify if there is a statistical significance to any of the demographic data on tenure.  One area to look at is concordance, which measures the goodness of fit.  Concordance is 0.5 when the model is as accurate as random chance, and 1.0 when the model is a perfect prediction.  A concordance of over 0.8 indicates a strong model, as long as its confidence interval does not extend below 0.5 in the range (Glen, 2020).  
A p-test can be used for the model and also for the factors in the model.  The smaller the p-value, the more confidence we can place in the model; generally, under 0.05 is a standard.  The Wald test is useful in identifying the p-value for the model.
Reporting
One of the values of using the Cox Proportional Hazard Model is being able to look at the data over time.  A fictional data set can help explain how the different graphs work.
Cumulative Event  – This graph shows the percentage of terminations (events) expected over time.  The percentage of the original populations who have terminated (from 0% to 100%) increases until all employees have terminated at around 1,000 days.  This chart indicates that females are leaving quicker than other populations.
Cumulative Hazard – Instead of looking at the expected number of terminations for the entire population, this graph expresses the same information as the risk someone will have terminated at a certain time.  This may be more useful in explaining the situation to an employee since it is based on their estimated risk of turnover.

Survival Probability % – Another way to to look at the results is to consider the chance someone will survive over a period of time.  A confidence interval was also added to this view (and could be added to any of the graphs).  We can see a wider confidence interval for the non-binary population; since there were fewer instances of non-binary employees, the model has less confidence in its projection of that population.

Model Testing with Diversity Data
Although a balanced dummy dataset is not useful in identifying bias (since there is none), it can help us identify false positives, so we know how well to trust this method.  By running the balanced dataset multiple times (using different random variables) we can see how often it falsely identifies bias.  This was done with organizations of different headcounts with 12 years of data, passing 6 racial categories, 3 gender categories, and 8 divisions through the Cox Proportional Hazard model.  The first round of testing looked at 3 fictional populations for organizations with headcounts of 20, 200, 2,000 and 20,000.
The first test looked at the number of factors that passed the p-test of being lower than 0.05 across any demographic or department, implying statistical significance.  All headcount levels had some tests that scored lower than 0.05, but the organizations with 20 employees identified more areas than any other category.

The second test looked at which models passed the Ward p-test.  Two of the organizations at the headcount level of 20 had a p-test of <2e-16, significantly under 0.05 which implies it is significant.  All other tests were over 0.05, showing the models should not be used.  (Gray box indicates area above 0.05)

The third test looked at the concordance.  All three organizations at the headcount level of 20 had over a 0.8 concordance, implying significance.  All other categories were around 0.6 or below, implying they should not be used.

Considering all of these together, only the first and third organizations with 20 employees passed all tests, indicating bias for 5 and 7 areas, respectively.  Since this fictional data is not influenced by structural or unconscious bias, finding indications at this headcount level implies that organizations at that size may be too small for this method of DEIB analysis.  The next tests look to identify validity for organizations with headcounts between 20 and 200.

The second round of tests created 10 organizations for each  headcount level: 20, 50, 100, and 150.  

The first test showed that all levels had organizations with factors that passed the 0.05 p-test at all headcount levels.

The second test identified organizations that passed the Ward p-test.  All headcount levels had one or two organizations that had under 0.05 for the Ward p-test, implying that they are significant.

The third test looked at the concordance.  For the organizations with 20 employees, 7 of the 10 had over 0.8 concordance.  No other headcount level had any organization with concordance over 0.8.  

For the second round of testing, 2 of 10 organizations with 20 employees passed all tests, implying there is statistically significant bias.  No other levels had any organizations that identified bias where there was none.  Taking all of these results into consideration, it appears that the Cox Proportional Hazard model is not a good tool for DEIB analysis for organizations under 50 employees.  

How Human Resources Responds
Reporting or statistical methods can give insights from the data, but they cannot prove what is happening in reality.  Using the Cox Proportional Hazard model is no different; the Human Resources team uses the indicators of shorter tenure as a tool to focus resources into specific populations to help identify the issue or to balance against it.

Identifying Issues through Researching Results
When a Human Resources team sees indicators of a problem, it often looks for other indicators to verify the issue.  If survival analysis indicates a statistically significant shorter tenure for one population, the HR team should look at other sources to find if they can provide other insights that show why this is happening or disprove it.  Examples include:

Do previous employee survey/pulse survey results show some reason this population is less satisfied than other populations?
Are there themes in exit interviews that connect this population’s resignations?
Is there qualitative information that focus groups could provide?
Are the employees in this population leaving for significantly better roles (indicating there may be something drawing them from our organization) or lateral/worse roles (indicating that they may feel pushed out) in comparison to similar populations? 
If there are indicators of a problem, these can further be explored in new survey questions, not only for this team but across the company.  This can further help identify if the issue is localized or if there are other areas where it is found.
Although most time consuming, the best method for understanding the situation is often to speak directly to the employees one-on-one.  It would be useful to speak to the affected population and to the non-affected population to understand differences in employee experience.  After speaking to the employees, having conversations with the leadership of this area may also help expose unconscious or structural bias causing the challenging situation.

Balance Against Bias
Structural and unconscious biases by their nature can be very challenging to identify.  Since these are often overlooked by traditional HR analytics, it is even more important to create a system to find and address them.  Although harder to find, they are as detrimental as any other form of bias.
Structural bias could be, for example, as simple as a recruiter only hiring from Ivy League schools.  Since these schools are disproportionately white, the candidate pool will be disproportionately white.  Even without knowing the cause of the issue (the recruiter’s strong preference for a non-representative population), we can still balance against it by focusing efforts on hiring more people from underrepresented groups.
Unconscious bias is buried in someone’s perception of reality.  By its nature, it is not understood by the person with the bias.  Sometimes an outside perspective can help find and address it, but often the interest, time, and resources needed to do that are not accessible in a business environment.  Without balancing against unconscious bias, over time the bias can create a problematic environment.
If an HR team identifies there is a problem with the environment for a certain population but cannot identify the cause of the problem (or can identify it but can not fix it), there are still ways to work to improve the situation.  Shifting leadership to different teams and creating cross-functional teams can give space for the disenfranchised groups to be successful.  By creating different environments, it may also help identify the problems in the original one.
It may also be possible to balance against the problem by hiring more people from the disenfranchised population to help decrease the culture of bias against them.  Hiring more people from this population may not decrease the cause of the bias against them (unfortunately, it may increase it), but if that group grows large enough it may be hard to implement bias against it.  This is especially true if people from the disenfranchised group take over leadership positions.  Demographic shifts and public conversations about bias may be even enough to encourage the person perpetrating the bias to shift their beliefs or leave the organization.  

Citations

Bonilla-Silva, E. (1997). Rethinking Racism: Toward a Structural Interpretation. American Sociological Review, 62(3), 465–480. https://doi.org/10.2307/2657316

Cox Proportional-Hazards Model. (n.d.). Statistical Tools for High-Throughput Data Analysis. Retrieved July 1, 2022, from http://sthda.com/english/wiki/cox-proportional-hazards-model

Culture Amp. (n.d.). The science behind the Inclusion survey. Https://Support.Cultureamp.Com/Hc/En-Us/Articles/360001319949-The-Science-behind-the-Inclusion-Survey. Retrieved July 18, 2022, from https://support.cultureamp.com/hc/en-us/articles/360001319949-The-science-behind-the-Inclusion-survey

Deo, S., Deo, V., & Sundaram, V. (2021, February 1). Survival analysis—part 2: Cox proportional hazards model. National 	Library of 	Medicine. Retrieved August 1, 2022, from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7876211/

Equal Employment Opportunity Tabulation Frequently Asked Questions (FAQs). (2022, January 5). U.S. Department of Labor. Retrieved June 12, 2022, from https://www.dol.gov/agencies/ofccp/faqs/EEO-Tab-FAQs#Q5

Fanon, F. (2008). Black Skin, White Masks (New Edition) [E-book]. Pluto Press. Retrieved June 12, 2022, from https://search-ebscohost-com.proxy.library.nyu.edu/login.aspx?direct=true&db=nlebk&AN=247433&site=ehost-live.

Glen, S. (2020, July 7). C-Statistic: Definition, Examples, Weighting and Significance. StatisticsHowTo.Com: Elementary Statistics 	for the Rest of Us! Retrieved August 1, 2022, from https://www.statisticshowto.com/c-statistic/

Green, J. (2022, February 16). Female Executive Pay Gap Widens to 25%, Biggest Gulf Since 2012. Bloomberg. Retrieved July 1, 2022, from https://www.bloomberg.com/news/articles/2022-02-16/female-executives-earned-25-less-than-men-do-a-nine-year-high

Hanson, S., & Tomaskovic-Devey, D. (1994). Gender &amp; Racial Inequality at Work: The Sources and Consequences of Job Segregation. Economic Geography, 70(3), 319. https://doi.org/10.2307/144001

Kehoe, T. (2019, April 11). What counts as a “business”? It might not be what you think it is. Albany Business Review. Retrieved July 1, 2022, from https://www.bizjournals.com/albany/news/2019/04/11/number-of-businesses-in-the-united-states.html

Kim, J. Y., & Roberson, L. (2022). I’m biased and so are you. What should organizations do? A review of organizational implicit-bias training programs. Consulting Psychology Journal, 74(1), 19–39. https://psycnet-apa-org.proxy.library.nyu.edu/fulltext/2022-16084-001.html

LaMorte, W. (2016, June 3). Cox Proportional Hazards Regression Analysis. Boston University - MPH Online Learning Modules. 	Retrieved August 1, 2022, from 	https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_survival/BS704_Survival6.html

Marsh McLennan. (n.d.). Customized Workday Executive Dashboards. Mercer. Retrieved July 18, 2022, from https://www.imercer.com/products/workday-executive-dashboards

McNulty, K. (2021). 9 Survival Analysis for Modeling Singular Events Over Time. Handbook of Regression Modeling in People Analytics. Retrieved June 13, 2022, from https://peopleanalytics-regression-book.org/survival.html

Singh, R., & Mukhopadhyay, K. (2011, December). Survival analysis in clinical trials: Basics and must know areas. National 	Library of Medicine. Retrieved August 1, 2022, from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3227332

SoftwareConnect. (2022, February 9). Workday HCM | 2022 Software Reviews, Pricing, Demos. Retrieved July 18, 2022, from https://softwareconnect.com/human-capital-management/workday-hcm/

Stevens, P. (2020, June 15). Companies are making bold promises about greater diversity, but there’s a long way to go. CNBC. Retrieved July 1, 2022, from https://www.cnbc.com/2020/06/11/companies-are-making-bold-promises-about-greater-diversity-theres-a-long-way-to-go.html

Williams, D. R., Lawrence, J. A., & Davis, B. A. (2019). Racism and Health: Evidence and Needed Research. Annual Review of Public Health, 40(1), 105–125. https://doi.org/10.1146/annurev-publhealth-040218-043750
